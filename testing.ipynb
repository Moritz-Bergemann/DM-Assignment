{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "## START ##\n",
    "# Load libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data2021.student.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get some basic data\n",
    "print(f\"Columns (Counted): {len(df.columns)}\")\n",
    "print(df.columns)\n",
    "\n",
    "print(f\"Row Count: {len(df)}\")\n",
    "\n",
    "print(\"Summary:\")\n",
    "df.describe()\n",
    "\n",
    "print(\"Unique:\")\n",
    "df.nunique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(f\"\\t\")\n",
    "\n",
    "## Column Investigation ##\n",
    "## Unique Values\n",
    "print(\"Unique Values\")\n",
    "lt_20_unique = [col for col in df.columns if df[col].nunique() <= 20]\n",
    "print(f\"\\tThe following columns have 20 or less unique values (likely categorical): {lt_20_unique}\")\n",
    "\n",
    "print(\"Converting classes with less than 10 unique values to categorical...\")\n",
    "df[lt_20_unique] = df[lt_20_unique].astype('category')\n",
    "print(\"Done!\")\n",
    "\n",
    "## Missing Values\n",
    "print(\"\\nMissing Values:\")\n",
    "# Find cols with any missing values\n",
    "cols_with_missing = [col for col in df.columns if df[col].isnull().sum() > 0]\n",
    "print(f\"\\tThe following columns have missing values: {cols_with_missing}\")\n",
    "\n",
    "# Find number of missing values per col\n",
    "# Get proportion of each one missing\n",
    "missing_ratios = [df[col].isnull().sum()/len(df) for col in df.columns]\n",
    "missing_ratios_dict = {col:ratio for (col, ratio) in zip(list(df.columns), missing_ratios) if ratio > 0}\n",
    "print(f\"\\tThe followng are the per-column missing data ratios: {missing_ratios_dict}\")\n",
    "\n",
    "## Useless Data\n",
    "print(\"\\nUseless Data:\")\n",
    "print(f\"\\tClass is just a label, so it's obviously useless\") # TODO way to demonstrate this?\n",
    "\n",
    "\n",
    "## Duplicate Columns\n",
    "print(\"\\nDuplicate Columns:\")\n",
    "\n",
    "print(\"Analysing column correlations\")\n",
    "# Numeric columns\n",
    "numeric_cors = df.corr()\n",
    "with open(\"corr.txt\", \"w\") as text_file:\n",
    "    text_file.write(numeric_cors.to_string())\n",
    "print(\"Numeric column correlation matrix saved to 'corr.txt'\")\n",
    "\n",
    "# Categorical Columns\n",
    "cat_cors = df.select_dtypes(include='category').apply(lambda x : pd.factorize(x)[0]).corr()\n",
    "print(\"BEANS\")\n",
    "print(type(cat_cors))\n",
    "\n",
    "with open(\"cat_corr.txt\", \"w\") as text_file:\n",
    "    text_file.write(cat_cors.to_string())\n",
    "plt.matshow(cat_cors)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDuplicate Rows:\")\n",
    "# duplicate_rows = df.iloc[]\n",
    "df_no_id = df.drop(['ID'], axis=1)\n",
    "duplicate_rows = df[df_no_id.duplicated()]\n",
    "print(f\"\\tBasic row duplication search identified {len(duplicate_rows)} duplicate rows: {list(duplicate_rows['ID'])}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\t\n",
      "Unique Values\n",
      "\tThe following columns have 20 or less unique values (likely categorical): ['Class', 'C2', 'C3', 'C5', 'C6', 'C7', 'C8', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C17', 'C18', 'C20', 'C21', 'C22', 'C23', 'C24', 'C26', 'C27', 'C28', 'C29', 'C30', 'C32']\n",
      "Converting classes with less than 10 unique values to categorical...\n",
      "Done!\n",
      "\n",
      "Missing Values:\n",
      "\tThe following columns have missing values: ['Class', 'C3', 'C4', 'C11', 'C13', 'C29', 'C32']\n",
      "\tThe followng are the per-column missing data ratios: {'Class': 0.09090909090909091, 'C3': 0.006363636363636364, 'C4': 0.006363636363636364, 'C11': 0.9954545454545455, 'C13': 0.005454545454545455, 'C29': 0.005454545454545455, 'C32': 0.9954545454545455}\n",
      "\n",
      "Useless Data:\n",
      "\tClass is just a label, so it's obviously useless\n",
      "\n",
      "Duplicate Columns:\n",
      "Analysing column correlations\n",
      "Numeric column correlation matrix saved to 'corr.txt'\n",
      "\n",
      "Duplicate Rows:\n",
      "\tBasic row duplication search identified 100 duplicate rows: [901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}