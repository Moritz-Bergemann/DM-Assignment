{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import data_prep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Get the preprocessed dataset\n",
    "df = data_prep.get_cleaned_dataset()\n",
    "\n",
    "print(df.dtypes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#####################\n",
    "### FUNCTION DEFS ###\n",
    "#####################\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prep_dataset(df, test_size=0.2):\n",
    "    # Separate labels & classes\n",
    "    X = df.drop('Class', axis=1).values     # Labels\n",
    "    y = df['Class'].values                  # Classes\n",
    "\n",
    "    X = OneHotEncoder().fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "from sklearn.metrics import confusion_matrix # TODO confusion matrix\n",
    "\n",
    "def basic_predict(X_train, X_test, y_train, y_test, classifier):\n",
    "    \"\"\"\n",
    "    Runs basic prediction with \n",
    "    :returns double indicating performance\n",
    "    NOTE: Random train/test split means performance is not consistent\n",
    "    \"\"\"\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_test_predict = classifier.predict(X_test)\n",
    "\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "    result = np.array([y_test_predict[ii] == y_test[ii] for ii in range(len(y_test))])\n",
    "\n",
    "    performance = np.count_nonzero(result)/len(result)\n",
    "\n",
    "    return performance"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Dataset\n",
    "df = data_prep.get_cleaned_dataset()\n",
    "\n",
    "X_train, X_test, y_train, y_test = prep_dataset(df, test_size=0.9966)\n",
    "\n",
    "# K-Nearest Neighbours\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_perf = basic_predict(X_train, X_test, y_train, y_test, knn)\n",
    "\n",
    "# Decision Tree \n",
    "# TODO use something other than decision tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt_perf = basic_predict(X_train, X_test, y_train, y_test, dt)\n",
    "\n",
    "# Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb_perf = basic_predict(X_train, X_test, y_train, y_test, dt)\n",
    "\n",
    "print(f\"knn performance: {knn_perf}\")\n",
    "print(f\"dt performance: {dt_perf}\")\n",
    "print(f\"gnb performance: {gnb_perf}\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "###########\n",
    "### OLD ###\n",
    "###########\n",
    "\n",
    "# Try some knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "train_test_ratio = 0.8\n",
    "\n",
    "performance_arr = []\n",
    "\n",
    "for n in range(1, 101):\n",
    "    knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "    last_train_row = int(len(df) * train_test_ratio)\n",
    "\n",
    "    X = df.drop('Class', axis=1).values     # Labels\n",
    "    y = df['Class'].values                  # Classes\n",
    "\n",
    "    X = OneHotEncoder().fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_predict = knn.predict(X_test)\n",
    "\n",
    "    result = np.array([y_predict[ii] == y_test[ii] for ii in range(len(y_test))])\n",
    "\n",
    "    performance = np.count_nonzero(result)/len(result)\n",
    "\n",
    "    performance_arr.append(performance)\n",
    "\n",
    "best_n = performance_arr.index(max(performance_arr))\n",
    "print(best_n)\n",
    "\n",
    "print(performance_arr[best_n])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "#########################################\n",
    "## Pipeline 1: K-Fold Cross-Validation ##\n",
    "#########################################\n",
    "## Missing: hparams, attribute selection, meta-classifiers ##\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import data_prep\n",
    "\n",
    "# Get dataset (mix of categorical & numeric)\n",
    "df_train, df_test = data_prep.get_prepped_dataset(bins=10, verbose=False)\n",
    "\n",
    "full = df_train.to_numpy()\n",
    "\n",
    "# Define values & labels\n",
    "X = df_train.drop('Class', axis=1).to_numpy()\n",
    "y = df_train['Class'].to_numpy()\n",
    "\n",
    "# Perform one-hot encoding on categorical values\n",
    "X = OneHotEncoder().fit_transform(X)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "result = cross_val_score(knn, X, y, cv=5)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.70555556 0.72222222 0.70555556 0.68333333 0.72777778]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "#############################################################\n",
    "## Pipeline 2: K-Fold Cross-Validation & Feature Selection ##\n",
    "#############################################################\n",
    "## Missing: hparams, attribute selection, meta-classifiers ##\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20) TODO do this later!!!\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import data_prep\n",
    "\n",
    "# Get dataset (mix of categorical & numeric)\n",
    "df_train, df_test = data_prep.get_prepped_dataset(bins=10, verbose=False)\n",
    "\n",
    "full = df_train.to_numpy()\n",
    "\n",
    "# Define values & labels\n",
    "X = df_train.drop('Class', axis=1).to_numpy()\n",
    "y = df_train['Class'].to_numpy()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Build pipeline\n",
    "pl = Pipeline([\n",
    "    ('onehot', OneHotEncoder()),\n",
    "    ('sfs', SequentialFeatureSelector(knn, direction='backward', n_features_to_select=None, cv=5)) # TODO change these params\n",
    "])\n",
    "\n",
    "print(\"Starting pipeline fit...\")\n",
    "pl.fit(X, y)\n",
    "\n",
    "# Try removing all 2 pairs of features to see what gets the best performance\n",
    "print(\"Done!\")\n",
    "with open('pipeline_2', 'wb') as f:\n",
    "    pickle.dump(pl, f)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pipeline(steps=[('onehot', OneHotEncoder()),\n",
      "                ('knn', KNeighborsClassifier(n_neighbors=3))])\n",
      "Starting pipeline fit...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'bin-6'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11870/4159648985.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting pipeline fit...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0msfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Try removing all 2 pairs of features to see what gets the best performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_selection/_sequential.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \"\"\"\n\u001b[1;32m    133\u001b[0m         \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    872\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    671\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'bin-6'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "###############\n",
    "## NEW THING ##\n",
    "###############\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# messing about with the created object\n",
    "df_train, df_test = data_prep.get_prepped_dataset(bins=10, verbose=False)\n",
    "\n",
    "with open('./pipeline_2', 'rb') as f:\n",
    "    result:Pipeline = pickle.load(f)\n",
    "\n",
    "sfs:SequentialFeatureSelector = result.named_steps['sfs']\n",
    "print(sfs.get_support().shape)\n",
    "\n",
    "# test = df_train.to_numpy()\n",
    "# X = df_train.drop('Class', axis=1).to_numpy()\n",
    "# y = df_train['Class'].to_numpy()\n",
    "\n",
    "# score = accuracy_score(result.predict(X), y)\n",
    "# print(score)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(118,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "####################################################################\n",
    "## Pipeline 3: K-Fold Cross-Validation & SMOTE ##\n",
    "####################################################################\n",
    "## Missing: hparams, attribute selection, meta-classifiers ##\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from im\n",
    "\n",
    "import data_prep\n",
    "\n",
    "\n",
    "# Get dataset (mix of categorical & numeric)\n",
    "df_train, df_test = data_prep.get_prepped_dataset(bins=10, verbose=False)\n",
    "\n",
    "full = df_train.to_numpy()\n",
    "\n",
    "# Define values & labels\n",
    "X = df_train.drop('Class', axis=1).to_numpy()\n",
    "y = df_train['Class'].to_numpy()\n",
    "\n",
    "# Build pipeline\n",
    "pl = Pipeline([\n",
    "    ('oh', OneHotEncoder()), \n",
    "    ('smote', SMOTE())\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=3))\n",
    "])\n",
    "\n",
    "knn = \n",
    "\n",
    "print(\"Done!\")\n",
    "with open('pipeline_2', 'wb') as f:\n",
    "    pickle.dump(sfs, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "arr = np.array(['A', 'B', 'C', 'A', 'C'])\n",
    "\n",
    "arr = arr.reshape(-1, 1)\n",
    "\n",
    "arr_oh = OneHotEncoder().fit_transform(arr)\n",
    "\n",
    "print(arr_oh)\n",
    "print(type(arr_oh))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (4, 2)\t1.0\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}