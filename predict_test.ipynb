{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import data_prep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Get the preprocessed dataset\n",
    "df = data_prep.get_cleaned_dataset()\n",
    "\n",
    "print(df.dtypes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#####################\n",
    "### FUNCTION DEFS ###\n",
    "#####################\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prep_dataset(df, test_size=0.2):\n",
    "    # Separate labels & classes\n",
    "    X = df.drop('Class', axis=1).values     # Labels\n",
    "    y = df['Class'].values                  # Classes\n",
    "\n",
    "    X = OneHotEncoder().fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "from sklearn.metrics import confusion_matrix # TODO confusion matrix\n",
    "\n",
    "def basic_predict(X_train, X_test, y_train, y_test, classifier):\n",
    "    \"\"\"\n",
    "    Runs basic prediction with \n",
    "    :returns double indicating performance\n",
    "    NOTE: Random train/test split means performance is not consistent\n",
    "    \"\"\"\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_test_predict = classifier.predict(X_test)\n",
    "\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "    result = np.array([y_test_predict[ii] == y_test[ii] for ii in range(len(y_test))])\n",
    "\n",
    "    performance = np.count_nonzero(result)/len(result)\n",
    "\n",
    "    return performance"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Dataset\n",
    "df = data_prep.get_cleaned_dataset()\n",
    "\n",
    "X_train, X_test, y_train, y_test = prep_dataset(df, test_size=0.9966)\n",
    "\n",
    "# K-Nearest Neighbours\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_perf = basic_predict(X_train, X_test, y_train, y_test, knn)\n",
    "\n",
    "# Decision Tree \n",
    "# TODO use something other than decision tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt_perf = basic_predict(X_train, X_test, y_train, y_test, dt)\n",
    "\n",
    "# Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb_perf = basic_predict(X_train, X_test, y_train, y_test, dt)\n",
    "\n",
    "print(f\"knn performance: {knn_perf}\")\n",
    "print(f\"dt performance: {dt_perf}\")\n",
    "print(f\"gnb performance: {gnb_perf}\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "###########\n",
    "### OLD ###\n",
    "###########\n",
    "\n",
    "# Try some knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "train_test_ratio = 0.8\n",
    "\n",
    "performance_arr = []\n",
    "\n",
    "for n in range(1, 101):\n",
    "    knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "    last_train_row = int(len(df) * train_test_ratio)\n",
    "\n",
    "    X = df.drop('Class', axis=1).values     # Labels\n",
    "    y = df['Class'].values                  # Classes\n",
    "\n",
    "    X = OneHotEncoder().fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_predict = knn.predict(X_test)\n",
    "\n",
    "    result = np.array([y_predict[ii] == y_test[ii] for ii in range(len(y_test))])\n",
    "\n",
    "    performance = np.count_nonzero(result)/len(result)\n",
    "\n",
    "    performance_arr.append(performance)\n",
    "\n",
    "best_n = performance_arr.index(max(performance_arr))\n",
    "print(best_n)\n",
    "\n",
    "print(performance_arr[best_n])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "#########################################\n",
    "## Pipeline 1: K-Fold Cross-Validation ##\n",
    "#########################################\n",
    "## Missing: hparams, attribute selection, meta-classifiers ##\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import data_prep\n",
    "\n",
    "# Get dataset (mix of categorical & numeric)\n",
    "df_train, df_test = data_prep.get_prepped_dataset(bins=10, verbose=False)\n",
    "\n",
    "full = df_train.to_numpy()\n",
    "\n",
    "# Define values & labels\n",
    "X = df_train.drop('Class', axis=1).to_numpy()\n",
    "y = df_train['Class'].to_numpy()\n",
    "\n",
    "# Perform one-hot encoding on categorical values\n",
    "X = OneHotEncoder().fit_transform(X)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "result = cross_val_score(knn, X, y, cv=5)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.70555556 0.72222222 0.70555556 0.68333333 0.72777778]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#############################################################\n",
    "## Pipeline 2: K-Fold Cross-Validation & Feature Selection ##\n",
    "#############################################################\n",
    "## Missing: hparams, attribute selection, meta-classifiers ##\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20) TODO do this later!!!\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import data_prep\n",
    "\n",
    "# Get dataset (mix of categorical & numeric)\n",
    "df_train, df_test = data_prep.get_prepped_dataset(bins=10, verbose=False)\n",
    "\n",
    "full = df_train.to_numpy()\n",
    "\n",
    "# Define values & labels\n",
    "X = df_train.drop('Class', axis=1).to_numpy()\n",
    "y = df_train['Class'].to_numpy()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Build pipeline\n",
    "pl = Pipeline([\n",
    "    ('onehot', OneHotEncoder()),\n",
    "    ('sfs', SequentialFeatureSelector(knn, direction='backward', n_features_to_select=None, cv=5)) # TODO change these params\n",
    "])\n",
    "\n",
    "print(\"Starting pipeline fit...\")\n",
    "pl.fit(X, y)\n",
    "\n",
    "# Try removing all 2 pairs of features to see what gets the best performance\n",
    "print(\"Done!\")\n",
    "with open('pipeline_2', 'wb') as f:\n",
    "    pickle.dump(pl, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "###############\n",
    "## NEW THING ##\n",
    "###############\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# messing about with the created object\n",
    "df_train, df_test = data_prep.get_prepped_dataset(bins=10, verbose=False)\n",
    "\n",
    "with open('./pipeline_2', 'rb') as f:\n",
    "    result:Pipeline = pickle.load(f)\n",
    "\n",
    "sfs:SequentialFeatureSelector = result.named_steps['sfs']\n",
    "print(sfs.get_support().shape)\n",
    "\n",
    "# test = df_train.to_numpy()\n",
    "# X = df_train.drop('Class', axis=1).to_numpy()\n",
    "# y = df_train['Class'].to_numpy()\n",
    "\n",
    "# score = accuracy_score(result.predict(X), y)\n",
    "# print(score)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(118,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "####################################################################\n",
    "## Pipeline 3: K-Fold Cross-Validation & SMOTE ##\n",
    "####################################################################\n",
    "## Missing: hparams, attribute selection, meta-classifiers ##\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, StratifiedKFold, KFold, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE, SMOTEN\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "\n",
    "import data_prep\n",
    "\n",
    "\n",
    "# Get dataset (mix of categorical & numeric)\n",
    "df_train, df_test = data_prep.get_prepped_dataset(bins=10, verbose=False)\n",
    "\n",
    "full = df_train.to_numpy()\n",
    "\n",
    "# Define values & labels\n",
    "X = df_train.drop('Class', axis=1).to_numpy()\n",
    "y = df_train['Class'].to_numpy()\n",
    "\n",
    "# Label-encode the labels  \n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Build imblearn pipeline with nominal SMOTE\n",
    "# ipl = make_pipeline(\n",
    "#     SMOTEN(random_state=123, sampling_strategy='not minority'),\n",
    "#     OneHotEncoder()\n",
    "# )\n",
    "\n",
    "# X_r, y_r = ipl.fit_resample(X, y)\n",
    "\n",
    "# for col in df_train.drop('Class', axis=1).columns:\n",
    "#     print(list(df_train[col].cat.categories))\n",
    "\n",
    "# Get list of categories per column\n",
    "categories = [list(df_train[col].cat.categories) for col in df_train.drop('Class', axis=1).columns]\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "pl = imbpipeline(steps= [\n",
    "        ('smoten', SMOTEN(random_state=123, sampling_strategy='not majority')),\n",
    "        ('onehot', OneHotEncoder(categories=categories)),\n",
    "        ('classifier', classifier)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pl.fit(X, y)\n",
    "\n",
    "# K-Fold Cross validation generator\n",
    "# NOTE: Stratified K-Fold used to ensure training classes are balanced (gives better representation of SMOTE-enabled prediction)\n",
    "# kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "scores = cross_validate(pl, X, y, cv=kfold, scoring=('accuracy', 'balanced_accuracy', 'f1', 'precision', 'recall'))\n",
    "print(\"SCORES\")\n",
    "print(scores)\n",
    "\n",
    "preds = cross_val_predict(pl, X, y, cv=kfold)\n",
    "\n",
    "conf_mat = confusion_matrix(y_pred=preds, y_true=y, normalize='all')\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(conf_mat)\n",
    "\n",
    "sns.heatmap(conf_mat, annot=True)\n",
    "\n",
    "# Get label proportions\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "counts = np.array([val/len(y) for val in counts])\n",
    "label_proportions = dict(zip(unique, counts))\n",
    "print(label_proportions)\n",
    "\n",
    "\n",
    "# THIS WORKY ######################################################\n",
    "# print(f\"Pre-SMOTE shape: {X.shape}\")\n",
    "\n",
    "# smoten = SMOTEN(random_state=123, sampling_strategy='not majority')\n",
    "# X_r, y_r = smoten.fit_resample(X, y)\n",
    "\n",
    "# print(f\"Post-SMOTE shape: {X_r.shape}\")\n",
    "\n",
    "# oh_enc = OneHotEncoder()\n",
    "# X_r = oh_enc.fit_transform(X_r)\n",
    "\n",
    "# print(f\"Post-Onehot shape: {X_r.shape}\")\n",
    "\n",
    "# l_enc = LabelEncoder()\n",
    "# y_r = l_enc.fit_transform(y_r)\n",
    "# /THIS WORKY #####################################################\n",
    "\n",
    "# print(X_r)\n",
    "# np.savetxt('./x.txt', X_r, fmt='%s')\n",
    "\n",
    "# print(\"Done!\")\n",
    "# with open('pipeline_2', 'wb') as f:\n",
    "#     pickle.dump(sfs, f)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SCORES\n",
      "{'fit_time': array([0.15035033, 0.14567733, 0.13880181, 0.15071917, 0.14050841]), 'score_time': array([0.01430297, 0.01490855, 0.01467252, 0.01465535, 0.01459575]), 'test_accuracy': array([0.68333333, 0.62777778, 0.61666667, 0.66666667, 0.7       ]), 'test_balanced_accuracy': array([0.65465755, 0.56060606, 0.55965909, 0.62962963, 0.67317229]), 'test_f1': array([0.5210084 , 0.37383178, 0.37837838, 0.49152542, 0.51785714]), 'test_precision': array([0.46969697, 0.33898305, 0.33333333, 0.453125  , 0.44615385]), 'test_recall': array([0.58490566, 0.41666667, 0.4375    , 0.53703704, 0.61702128])}\n",
      "CONFUSION MATRIX\n",
      "[[0.51444444 0.20777778]\n",
      " [0.13333333 0.14444444]]\n",
      "{0: 0.7222222222222222, 1: 0.2777777777777778}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "arr = np.array(['A', 'B', 'C', 'A', 'C'])\n",
    "\n",
    "arr = arr.reshape(-1, 1)\n",
    "\n",
    "arr_oh = OneHotEncoder().fit_transform(arr)\n",
    "\n",
    "print(arr_oh)\n",
    "print(type(arr_oh))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (4, 2)\t1.0\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}